{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eMRUuYFyQUJ"
   },
   "source": [
    "# Deep Learning with PyTorch\n",
    "\n",
    "Modified from the version created by Dr. [Jian Tao](https://orcid.org/0000-0003-4228-6089), Texas A&M University\n",
    "\n",
    "Oct 3, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8Hap6gZyQUL"
   },
   "source": [
    "## Deep Learning\n",
    "Deep Learning (DL) is one cagegory of machine learning methods that are based on artificial neural networks to improve computer algorithms automatically through data.\n",
    "\n",
    "DL methods can be devided into:\n",
    "\n",
    "* Supervised Learning\n",
    "    * trained with labeled data; including regression and classification problems\n",
    "* Unsupervised Learning\n",
    "    * trained with unlabeled data; clustering and association rule learning problems.\n",
    "* Reinforcement Learning\n",
    "    * no training data; stochastic Markov decision process; robotics and self-driving cars.\n",
    "\n",
    "DL methods are useful primarily for the following reasons:\n",
    "\n",
    "* DL is computationally expensive, but it is capable of handling high dimensional data.\n",
    "* feature extraction is done automatically.\n",
    "\n",
    "![Deep Learning](https://github.com/happidence1/AILabs/blob/master/images/deeplearning.svg?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time  # Import the time module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download and prepare the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 2.083\n",
      "[1, 400] loss: 0.861\n",
      "[1, 600] loss: 0.436\n",
      "[1, 800] loss: 0.352\n",
      "[2, 200] loss: 0.249\n",
      "[2, 400] loss: 0.235\n",
      "[2, 600] loss: 0.201\n",
      "[2, 800] loss: 0.188\n",
      "[3, 200] loss: 0.153\n",
      "[3, 400] loss: 0.147\n",
      "[3, 600] loss: 0.117\n",
      "[3, 800] loss: 0.120\n",
      "[4, 200] loss: 0.104\n",
      "[4, 400] loss: 0.097\n",
      "[4, 600] loss: 0.095\n",
      "[4, 800] loss: 0.089\n",
      "[5, 200] loss: 0.087\n",
      "[5, 400] loss: 0.083\n",
      "[5, 600] loss: 0.078\n",
      "[5, 800] loss: 0.077\n",
      "[6, 200] loss: 0.072\n",
      "[6, 400] loss: 0.072\n",
      "[6, 600] loss: 0.068\n",
      "[6, 800] loss: 0.063\n",
      "[7, 200] loss: 0.061\n",
      "[7, 400] loss: 0.062\n",
      "[7, 600] loss: 0.063\n",
      "[7, 800] loss: 0.062\n",
      "[8, 200] loss: 0.051\n",
      "[8, 400] loss: 0.056\n",
      "[8, 600] loss: 0.056\n",
      "[8, 800] loss: 0.059\n",
      "[9, 200] loss: 0.051\n",
      "[9, 400] loss: 0.047\n",
      "[9, 600] loss: 0.053\n",
      "[9, 800] loss: 0.051\n",
      "[10, 200] loss: 0.042\n",
      "[10, 400] loss: 0.049\n",
      "[10, 600] loss: 0.046\n",
      "[10, 800] loss: 0.047\n",
      "Finished Training\n",
      "Training took 49.51250243186951 seconds\n"
     ]
    }
   ],
   "source": [
    "# Timing start\n",
    "start_time = time.time()\n",
    "# Training loop\n",
    "for epoch in range(10):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # Print every 200 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n",
    "# Timing end\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training took {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(net.state_dict(), 'mnist_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model for evaluation\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('mnist_net.pth'))\n",
    "net.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download and prepare the test dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.54%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on the test set: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "04_deep_learning_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
